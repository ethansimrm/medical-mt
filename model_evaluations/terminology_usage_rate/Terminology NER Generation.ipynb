{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2304685-007a-4efa-927f-9cf2fbce5179",
   "metadata": {},
   "source": [
    "# Named Entity Recognition Testing\n",
    "\n",
    "Previously, we used heuristic methods to identify terminology, but we can do better with named entity recognition. \n",
    "\n",
    "This notebook is run in Python 3.8, in a different virtual environment specified by the requirements in requirements_scispacy.txt. This is because SciSpacy cannot be installed in Python >= 3.9 due to an issue with the nmslib dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd25f7b-e6a6-469d-8b9f-7b8b86c5c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "dir_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09735347-26f9-4d4f-b0ab-b65c12c1afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open our test files first\n",
    "f = open(os.path.join(dir_path, \"../wmt22test.txt\"), \"r\", encoding = \"utf8\")\n",
    "en_sent = [line.strip() for line in f.readlines()]\n",
    "f.close()\n",
    "f = open(os.path.join(dir_path, \"../wmt22gold.txt\"), \"r\", encoding = \"utf8\")\n",
    "fr_sent = [line.strip() for line in f.readlines()]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f32f7f9-f094-4bd7-a1aa-4b859675cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#en_tagger = spacy.load(\"en_core_web_trf\") #We will use the same scibert model for EN tokenisation for consistency.\n",
    "fr_tagger = spacy.load(\"fr_dep_news_trf\")\n",
    "en_ner = spacy.load(\"en_core_sci_scibert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45aba311-c636-45c9-9731-88834b688714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Named entity recognition == terminology we must get right\n",
    "ner_locs = []\n",
    "ner_ents = []\n",
    "for sentence in en_sent:\n",
    "    test = en_ner(sentence).ents\n",
    "    ner_ents.append(test)\n",
    "    ner_locs.append([[i for i in range(t.start, t.end)] for t in test]) #Need to find where these tokens are, then perform lookup using alignments to obtain (predicted) translations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd7ed50e-627f-40a7-914f-9745a2423294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7], [9], [10], [12], [14], [15], [16, 17]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_locs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96413fff-c942-4277-ae27-5bcd654fc47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(systematic review,\n",
       " meta-analysis,\n",
       " investigating,\n",
       " evidence,\n",
       " treating,\n",
       " recalcitrant,\n",
       " auricular keloids)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_ents[3] #For cross-checking purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5871d68-bbdf-4d5a-acb6-c68b2976bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 588/588 [00:43<00:00, 13.43it/s]\n"
     ]
    }
   ],
   "source": [
    "en_tagged = []\n",
    "for sentence in tqdm(en_sent):\n",
    "    en_tagged_sent = en_ner(sentence)\n",
    "    en_tagged_tokenised = [token for token in en_tagged_sent] #We just need the text for each token, which we will index using ner_locs\n",
    "    en_tagged.append(en_tagged_tokenised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82572910-9456-44bf-8e09-b76c2b87f849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 588/588 [00:48<00:00, 12.14it/s]\n"
     ]
    }
   ],
   "source": [
    "fr_tagged = []\n",
    "for sentence in tqdm(fr_sent):\n",
    "    fr_tagged_sent = fr_tagger(sentence)\n",
    "    fr_tagged_tokenised = [token for token in fr_tagged_sent]\n",
    "    fr_tagged.append(fr_tagged_tokenised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07674e95-7fcd-4be2-8f82-9ab3884c0101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2023-06-25 23:19:38,779 - simalign.simalign - INFO - Initialized the EmbeddingLoader with model: bert-base-multilingual-cased\n"
     ]
    }
   ],
   "source": [
    "#Word alignment\n",
    "from simalign import SentenceAligner\n",
    "aligner = SentenceAligner(matching_methods=\"a\") #Argmax only; the simAlign paper stated that this gives the best performance for English-French alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd283aae-24ed-4482-84ff-74ec68bb869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 588/588 [01:28<00:00,  6.68it/s]\n"
     ]
    }
   ],
   "source": [
    "alignments_list = []\n",
    "for i in tqdm(range(len(en_tagged))):\n",
    "    src_sent = [token.text for token in en_tagged[i]]\n",
    "    tgt_sent = [token.text for token in fr_tagged[i]] \n",
    "    alignments = aligner.get_word_aligns(src_sent, tgt_sent)\n",
    "    alignments_list.append(alignments[\"inter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3a69f0f-cb86-4488-93fc-77efd38d2216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588\n",
      "588\n"
     ]
    }
   ],
   "source": [
    "#Use named entity tokens as keys to query their predicted translations, and therefore, gold-standard terminology.\n",
    "print(len(ner_locs))\n",
    "print(len(alignments_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11be2567-e00e-4001-973d-bb1d24c901c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3),\n",
       " (1, 2),\n",
       " (2, 1),\n",
       " (3, 4),\n",
       " (5, 6),\n",
       " (7, 7),\n",
       " (7, 8),\n",
       " (8, 11),\n",
       " (9, 12),\n",
       " (11, 13),\n",
       " (12, 14)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignments_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89e0d329-0942-4874-9f9d-d9b5ac71431c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prospective_ne_fr = []\n",
    "for i in range(len(alignments_list)):\n",
    "    ne_fr_per_sentence = []\n",
    "    for ne_token_span_list in ner_locs[i]: #Each line comprises a list of lists containing indices of all tokens comprising an NE span, e.g., \"Auricular keloid\"\n",
    "        for ne_token_idx in ne_token_span_list: #For each token which is part of an NE span\n",
    "            for alignment in alignments_list[i]:\n",
    "                if (alignment[0] == ne_token_idx):\n",
    "                    ne_fr_per_sentence.append(fr_tagged[i][alignment[1]]) #Find its aligned counterpart, BUT we cannot assume that words stick together (manual checking showed this)\n",
    "    prospective_ne_fr.append(ne_fr_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1751ee1-2c31-456b-bc14-5e5deb7102ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual inspection shows that a few terms aren't really terms - stuff like \"de\", etc. are prepositions. We should get rid of them using PoS tagging.\n",
    "import string\n",
    "ne_fr_pnav_only = [] #Proper nouns, nouns, adjectives, verbs\n",
    "for i in range(len(prospective_ne_fr)):\n",
    "    include = [token.text.replace(\"</i>\", \"\").replace(\"</sup\", \"\") #Some entity tags caught the HTML tags as well - this isn't part of terminology\n",
    "               for token in prospective_ne_fr[i] \n",
    "               if token.pos_ in [\"PROPN\", \"NOUN\", \"ADJ\", \"VERB\"] and #Filter only specific PoS - we know that adverbs, auxiliaries, prepositions etc are not terminologies. \n",
    "               #Medical terminology is mostly nouns and adjectives, but proper nouns and verbs denoting specific medical actions may be important too (subject to noise due to gender, etc.)\n",
    "               token.text not in string.punctuation] #Remove punctuation-only\n",
    "    ne_fr_pnav_only.append(include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12929b64-61ae-409c-99ce-840dd9b13d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At this point we almost have a candidate terminology. We just need to aggregate terminology counts per sentence. Let's flatten this into a pandas dataframe first.\n",
    "import pandas as pd\n",
    "sent_IDs = []\n",
    "terms = []\n",
    "for i in range(len(ne_fr_pnav_only)):\n",
    "    for term in ne_fr_pnav_only[i]:\n",
    "        sent_IDs.append(i)\n",
    "        terms.append(term)\n",
    "term_list = pd.DataFrame(data = {\"sent_ID\" : sent_IDs, \"term\" : terms})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b802c10b-1286-4117-a9be-be981ff1ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And we simply aggregate counts. We will take note of casing here, but generate a separate list without casing.\n",
    "def find_count_in_sentence_exact_match(row):\n",
    "    query = row[\"term\"]\n",
    "    return len([found for found in fr_tagged[row[\"sent_ID\"]] if query == found.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff428cb8-f312-437c-837b-abcd770bea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_list = term_list.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb6a03e7-3072-47dd-af93-552d3c19d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_list[\"count\"] = term_list.apply(find_count_in_sentence_exact_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3524eae6-3ded-4337-a227-edb6d1658049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_ID</th>\n",
       "      <th>term</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>récalcitrantes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>auriculaires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>chéloïdes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>traitement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>élevé</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>587</td>\n",
       "      <td>athlètes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>587</td>\n",
       "      <td>contraire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>587</td>\n",
       "      <td>fatigue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3457</th>\n",
       "      <td>587</td>\n",
       "      <td>dynamique</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>587</td>\n",
       "      <td>équilibre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3459 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_ID            term  count\n",
       "0           0  récalcitrantes      1\n",
       "1           0    auriculaires      1\n",
       "2           0       chéloïdes      1\n",
       "3           0      traitement      1\n",
       "4           1           élevé      1\n",
       "...       ...             ...    ...\n",
       "3454      587        athlètes      1\n",
       "3455      587       contraire      1\n",
       "3456      587         fatigue      1\n",
       "3457      587       dynamique      1\n",
       "3458      587       équilibre      1\n",
       "\n",
       "[3459 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecef73da-9b3c-4a01-8670-739d62c5fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(\"wmt22gold_terminology_ner.txt\", \"w\", encoding = \"utf8\")\n",
    "for i in range(len(term_list)):\n",
    "    output.write(str(term_list[\"sent_ID\"][i]) + \"\\t\" + term_list[\"term\"][i] + \"\\t\" + str(term_list[\"count\"][i]) + \"\\n\")\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "441a4890-52f6-4d8e-9e3a-1ef5e51b455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we will generate a separate list without casing, and aggregate counts as usual. Interestingly, we have the same number of rows, indicating that there are no terminologies which \n",
    "#appear multiple times within a single sentence, but with different casing. This means that we can stop here for now.\n",
    "#term_list_uncased = term_list[[\"sent_ID\", \"term\"]]\n",
    "#term_list_uncased[\"uncased_term\"] = term_list_uncased[\"term\"].apply(str.lower)\n",
    "#term_list_uncased = term_list_uncased.drop(columns = \"term\")\n",
    "#term_list_uncased = term_list_uncased.drop_duplicates().reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
