{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate sacrebleu transformers==4.28.0 #Avoid PartialState error with accelerate","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:22:05.298214Z","iopub.execute_input":"2023-05-25T22:22:05.298578Z","iopub.status.idle":"2023-05-25T22:22:28.187457Z","shell.execute_reply.started":"2023-05-25T22:22:05.298551Z","shell.execute_reply":"2023-05-25T22:22:28.186318Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sacrebleu\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting transformers==4.28.0\n  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (4.64.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.5.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.2)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (10.0.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.28.0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\nInstalling collected packages: portalocker, sacrebleu, transformers, evaluate\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.29.2\n    Uninstalling transformers-4.29.2:\n      Successfully uninstalled transformers-4.29.2\nSuccessfully installed evaluate-0.4.0 portalocker-2.7.0 sacrebleu-2.3.1 transformers-4.28.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"HF_KEY\")\nlogin(secret_value)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:22:28.189730Z","iopub.execute_input":"2023-05-25T22:22:28.190370Z","iopub.status.idle":"2023-05-25T22:22:29.327749Z","shell.execute_reply.started":"2023-05-25T22:22:28.190333Z","shell.execute_reply":"2023-05-25T22:22:29.326600Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"#Load in EN-FR subset of OPUS books\nfrom datasets import load_dataset, load_dataset_builder,concatenate_datasets\nbooks = load_dataset(\"ethansimrm/OpusTrain\") #Using the same dataset as Colab for consistency\nbooksTest = load_dataset(\"ethansimrm/OpusTest\") #Using the same dataset as Colab for consistency","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:22:29.329416Z","iopub.execute_input":"2023-05-25T22:22:29.330142Z","iopub.status.idle":"2023-05-25T22:22:54.234505Z","shell.execute_reply.started":"2023-05-25T22:22:29.330092Z","shell.execute_reply":"2023-05-25T22:22:54.233529Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset parquet/ethansimrm--OpusTrain to /root/.cache/huggingface/datasets/parquet/ethansimrm--OpusTrain-0e62f5268a5f0ef3/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0138620f4ebf41cba90efd7406aee1c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/19.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0b31085eb75470f8f49224e5735d933"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef242fcaa950472d8a46ccda1fbf93ca"}},"metadata":{}},{"name":"stdout","text":"Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ethansimrm--OpusTrain-0e62f5268a5f0ef3/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f033987d39a41e8ade4e99b45661e7b"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset parquet/ethansimrm--OpusTest to /root/.cache/huggingface/datasets/parquet/ethansimrm--OpusTest-e350203b885f5992/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9bf168be8f44bf1b9c804ea2e6d386e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.76M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6fdd915861e4a13bf882a0612b7d81a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c183b7f12f6245a0b3b066faef2b80ba"}},"metadata":{}},{"name":"stdout","text":"Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ethansimrm--OpusTest-e350203b885f5992/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e37b29aeba74fa68d15392835cfb496"}},"metadata":{}}]},{"cell_type":"code","source":"#ds_builder = load_dataset_builder(\"rotten_tomatoes\")\n#ds_builder = load_dataset_builder(\"wmt14\", 'fr-en')\n#ds_builder.info.description\n#ds_builder.info.features","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:22:54.237328Z","iopub.execute_input":"2023-05-25T22:22:54.238646Z","iopub.status.idle":"2023-05-25T22:22:54.245838Z","shell.execute_reply.started":"2023-05-25T22:22:54.238613Z","shell.execute_reply":"2023-05-25T22:22:54.241658Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Entirety of OPUS books is a training dataset, so split into train:test with 80:20.\n#books = books[\"train\"].train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:22:54.247402Z","iopub.execute_input":"2023-05-25T22:22:54.248162Z","iopub.status.idle":"2023-05-25T22:22:54.331720Z","shell.execute_reply.started":"2023-05-25T22:22:54.248115Z","shell.execute_reply":"2023-05-25T22:22:54.330771Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Inspect data; the split is random.\nbooks['train'][0]","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:22:54.333106Z","iopub.execute_input":"2023-05-25T22:22:54.333618Z","iopub.status.idle":"2023-05-25T22:22:54.343798Z","shell.execute_reply.started":"2023-05-25T22:22:54.333586Z","shell.execute_reply":"2023-05-25T22:22:54.342714Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'id': '67130',\n 'translation': {'en': 'Since he had grown to manhood they no longer said in so many words:\"Look at Jean and follow his example,\" but every time he heard them say\"Jean did this--Jean does that,\" he understood their meaning and thehint the words conveyed.',\n  'fr': \"Depuis qu'il était homme, on ne lui disait plus: «Regarde Jean etimite-le!» mais chaque fois qu'il entendait répéter: «Jean a fait ceci,Jean a fait cela,» il comprenait bien le sens et l'allusion cachés sousces paroles.\"}}"},"metadata":{}}]},{"cell_type":"code","source":"#Tokenise data - we must load the correct tokeniser for our model before we input parameters. This is based on SentencePiece.\nfrom transformers import AutoTokenizer\ncheckpoint = \"t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n#NB: As long as data looks like {\"input\" : \"XXXX\" , \"target\" : \"YYYY\"}, it can be processed.","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:22:54.345502Z","iopub.execute_input":"2023-05-25T22:22:54.345881Z","iopub.status.idle":"2023-05-25T22:22:59.308822Z","shell.execute_reply.started":"2023-05-25T22:22:54.345851Z","shell.execute_reply":"2023-05-25T22:22:59.307807Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7664aa8f4f5841ae89084b0b206008c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13ad29b532e042678d924935ad7bfe6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b37e24b072b451d95a531232fb333dc"}},"metadata":{}}]},{"cell_type":"code","source":"#Specify a preprocessing function which allows us to tokenise source and target languages correctly AND prime T5 with the correct prompt before each sentence\nsource_lang = \"en\"\ntarget_lang = \"fr\"\nprefix = \"translate English to French: \"\n\n\ndef preprocess_function(examples):\n    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]] \n    #We are essentially querying the dictionary here, whereby books[\"train\"][\"translation\"][0][\"en\"] references the first English sentence above.\n    targets = [example[target_lang] for example in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True) #We will truncate sentences longer than 128 words long\n    return model_inputs\n\n#books[\"train\"][\"translation\"][0][\"en\"] will give us the first English sentence","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:22:59.310427Z","iopub.execute_input":"2023-05-25T22:22:59.311378Z","iopub.status.idle":"2023-05-25T22:22:59.319772Z","shell.execute_reply.started":"2023-05-25T22:22:59.311342Z","shell.execute_reply":"2023-05-25T22:22:59.316731Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Apply this function over the training dataset over multiple elements simultaneously using the batched = True argument.\ntokenized_books = books.map(preprocess_function, batched=True)\ntokenized_booksTest = booksTest.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:22:59.321139Z","iopub.execute_input":"2023-05-25T22:22:59.321913Z","iopub.status.idle":"2023-05-25T22:23:29.081392Z","shell.execute_reply.started":"2023-05-25T22:22:59.321880Z","shell.execute_reply":"2023-05-25T22:23:29.080448Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2c2473c59094f33979df38d10a07e66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/26 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8706ae845ba4b67982436e8ae2db8a6"}},"metadata":{}}]},{"cell_type":"code","source":"#Create a batch of examples and dynamically pad to hit length of longest sentence per batch\nfrom transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n#Ignore the tensorflow linkage warning; Kaggle's conda forge does not have it","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:23:29.085122Z","iopub.execute_input":"2023-05-25T22:23:29.085805Z","iopub.status.idle":"2023-05-25T22:23:40.071683Z","shell.execute_reply.started":"2023-05-25T22:23:29.085771Z","shell.execute_reply":"2023-05-25T22:23:40.070729Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#Load evaluation method\nimport evaluate\nmetric = evaluate.load(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:23:40.072944Z","iopub.execute_input":"2023-05-25T22:23:40.074499Z","iopub.status.idle":"2023-05-25T22:23:43.470160Z","shell.execute_reply.started":"2023-05-25T22:23:40.074445Z","shell.execute_reply":"2023-05-25T22:23:43.469285Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"283e7d6eba5642d48bf226d06047f4a2"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef postprocess_text(preds, labels): \n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True) #Convert back into words\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id) #Ignore padded labels added by the data collator to the test set\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True) \n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels) #Remove leading and trailing spaces\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels) #BLEU score for provided input and references\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens) #Compute mean prediction length\n    result = {k: round(v, 4) for k, v in result.items()} #Round score to 4dp\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:23:43.471434Z","iopub.execute_input":"2023-05-25T22:23:43.472310Z","iopub.status.idle":"2023-05-25T22:23:43.484199Z","shell.execute_reply.started":"2023-05-25T22:23:43.472276Z","shell.execute_reply":"2023-05-25T22:23:43.483113Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Ready to download model\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint) #Model is 242MB in size","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:23:43.486297Z","iopub.execute_input":"2023-05-25T22:23:43.486613Z","iopub.status.idle":"2023-05-25T22:24:09.140626Z","shell.execute_reply.started":"2023-05-25T22:23:43.486577Z","shell.execute_reply":"2023-05-25T22:24:09.139716Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fcc8bff028b48cc869e032eab4cc091"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9653f04caa54b3197db3b2b3767375d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98dc0f2520e845719c42eb820787a404"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\ntraining_args = Seq2SeqTrainingArguments( #Collects hyperparameters\n    output_dir=\"test_t5_small_example_kaggle3\",\n    evaluation_strategy=\"epoch\", #Evaluates at the end of each epoch\n    learning_rate=2e-5, #Initial learning rate for AdamW\n    per_device_train_batch_size=16, #Minibatch learning\n    per_device_eval_batch_size=16, #Batch size for evaluation\n    weight_decay=0.01, #Weight decay for loss computation; Loss = Loss + WD * sum (weights squared)\n    save_total_limit=3, #Number of checkpoints to save\n    num_train_epochs=2,\n    predict_with_generate=True, #Use with ROUGE/BLEU and other translation metrics (see below)\n    fp16=True, #Remove fp16 = True if not using CUDA\n    push_to_hub=True,\n)\n\ntrainer = Seq2SeqTrainer( #Saves us from writing our own training loops\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_books[\"train\"],\n    eval_dataset=tokenized_booksTest[\"train\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\n#However, these metrics require that we generate some text with the model rather than a single forward pass as with e.g. classification. \n#The Seq2SeqTrainer allows for the use of the generate method when setting predict_with_generate=True which will generate text for each sample in the evaluation set. \n#That means we evaluate generated text within the compute_metric function. We just need to decode the predictions and labels first.","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:25:02.432047Z","iopub.execute_input":"2023-05-25T22:25:02.432411Z","iopub.status.idle":"2023-05-25T22:25:08.057643Z","shell.execute_reply.started":"2023-05-25T22:25:02.432381Z","shell.execute_reply":"2023-05-25T22:25:08.056650Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Cloning https://huggingface.co/ethansimrm/test_t5_small_example_kaggle3 into local empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T22:25:31.533706Z","iopub.execute_input":"2023-05-25T22:25:31.534072Z","iopub.status.idle":"2023-05-25T23:19:32.760618Z","shell.execute_reply.started":"2023-05-25T22:25:31.534045Z","shell.execute_reply":"2023-05-25T23:19:32.759546Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230525_222545-nalrda2c</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ethansimrm/huggingface/runs/nalrda2c' target=\"_blank\">denim-energy-3</a></strong> to <a href='https://wandb.ai/ethansimrm/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ethansimrm/huggingface' target=\"_blank\">https://wandb.ai/ethansimrm/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ethansimrm/huggingface/runs/nalrda2c' target=\"_blank\">https://wandb.ai/ethansimrm/huggingface/runs/nalrda2c</a>"},"metadata":{}},{"name":"stderr","text":"You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12710' max='12710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12710/12710 53:14, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.847500</td>\n      <td>1.636042</td>\n      <td>5.495200</td>\n      <td>17.611800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.814900</td>\n      <td>1.612160</td>\n      <td>5.681600</td>\n      <td>17.595500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=12710, training_loss=1.8734240756271205, metrics={'train_runtime': 3241.1958, 'train_samples_per_second': 62.735, 'train_steps_per_second': 3.921, 'total_flos': 5017466336575488.0, 'train_loss': 1.8734240756271205, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T23:24:57.651397Z","iopub.execute_input":"2023-05-25T23:24:57.652653Z","iopub.status.idle":"2023-05-25T23:25:43.620876Z","shell.execute_reply.started":"2023-05-25T23:24:57.652593Z","shell.execute_reply":"2023-05-25T23:25:43.619575Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload file pytorch_model.bin:   0%|          | 1.00/231M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"252d7c262eb44931a639536b1faab663"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload file runs/May25_22-25-02_2a7868de4d98/events.out.tfevents.1685053531.2a7868de4d98.28.0:   0%|          …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0719b3713d4f488917562e3c24a22e"}},"metadata":{}},{"name":"stderr","text":"To https://huggingface.co/ethansimrm/test_t5_small_example_kaggle3\n   f3c5813..b01232f  main -> main\n\nTo https://huggingface.co/ethansimrm/test_t5_small_example_kaggle3\n   b01232f..2cf1772  main -> main\n\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/ethansimrm/test_t5_small_example_kaggle3/commit/b01232fff60aa1c3451a1880dcb7f110afef79b4'"},"metadata":{}}]},{"cell_type":"code","source":"text = \"translate English to French: Legumes share resources with nitrogen-fixing bacteria.\"","metadata":{"execution":{"iopub.status.busy":"2023-05-25T23:26:36.903382Z","iopub.execute_input":"2023-05-25T23:26:36.904068Z","iopub.status.idle":"2023-05-25T23:26:36.910290Z","shell.execute_reply.started":"2023-05-25T23:26:36.904034Z","shell.execute_reply":"2023-05-25T23:26:36.908950Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\ntranslator = pipeline(\"translation\", model=\"test_t5_small_example_kaggle3\")\ntranslator(text)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T23:26:40.086707Z","iopub.execute_input":"2023-05-25T23:26:40.087599Z","iopub.status.idle":"2023-05-25T23:26:42.425305Z","shell.execute_reply.started":"2023-05-25T23:26:40.087557Z","shell.execute_reply":"2023-05-25T23:26:42.423998Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/__init__.py:958: UserWarning: \"translation\" task was used, instead of \"translation_XX_to_YY\", defaulting to \"translation_en_to_de\"\n  warnings.warn(\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[{'translation_text': 'Legumes teilen Ressourcen mit Stickstoff-fixierenden Bakterien.'}]"},"metadata":{}}]}]}