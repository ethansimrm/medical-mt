{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers[sentencepiece]==4.28.0 datasets sacrebleu evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"HF_KEY\")\nlogin(secret_value)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\n\nprint(transformers.__version__)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\nmetric = load_metric(\"sacrebleu\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data = load_dataset(\"news_commentary\", \"en-fr\") ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data = training_data['train'].train_test_split(test_size=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ncheckpoint = \"Helsinki-NLP/opus-mt-en-fr\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_lang = \"en\"\ntarget_lang = \"fr\"\nprefix = \"translate English to French: \"\ndef preprocess_function(examples):\n    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]] \n    targets = [example[target_lang] for example in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n    return model_inputs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_train = training_data.map(preprocess_function, batched=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef postprocess_text(preds, labels): \n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True) #Convert back into words\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id) #Ignore padded labels added by the data collator to the test set\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True) \n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels) #Remove leading and trailing spaces\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels) #BLEU score for provided input and references\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens) #Compute mean prediction length\n    result = {k: round(v, 4) for k, v in result.items()} #Round score to 4dp\n    return result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\ntraining_args = Seq2SeqTrainingArguments( #Collects hyperparameters\n    output_dir=\"t5_small_prelim_news\",\n    evaluation_strategy=\"epoch\", #Evaluates at the end of each epoch\n    learning_rate=2e-5, #Initial learning rate for AdamW\n    per_device_train_batch_size=16, #Minibatch learning\n    per_device_eval_batch_size=16, #Batch size for evaluation\n    weight_decay=0.01, #Weight decay for loss computation; Loss = Loss + WD * sum (weights squared)\n    save_total_limit=3, #Number of checkpoints to save\n    num_train_epochs=2,\n    predict_with_generate=True, #Use with ROUGE/BLEU and other translation metrics (see below)\n    fp16=True, #Remove fp16 = True if not using CUDA\n    push_to_hub=True,\n)\n\ntrainer = Seq2SeqTrainer( #Saves us from writing our own training loops\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train[\"train\"],\n    eval_dataset=tokenized_train[\"train\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{},"execution_count":null,"outputs":[]}]}